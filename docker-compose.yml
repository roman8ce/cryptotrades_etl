services:
  kafka:
    image: apache/kafka:3.8.1
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT_HOST://localhost:9092,PLAINTEXT://kafka:29092'
      KAFKA_LISTENERS: 'PLAINTEXT_HOST://0.0.0.0:9092,PLAINTEXT://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8082:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: 'local'
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: 'kafka:29092'

  postgres:
    image: postgres:15
    container_name: postgres
    ports:
      - 5432:5432
    environment: 
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql

  producer:
    build:
      context: ./producer
      dockerfile: Dockerfile
    container_name: producer
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_TOPIC=trades
    depends_on:
      - kafka
    restart: unless-stopped

  consumer:
    build:
      context: ./consumer
      dockerfile: Dockerfile
    container_name: consumer
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_TOPIC=trades
      - KAFKA_GROUP_ID=trades-consumer-group
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    depends_on:
      - kafka
      - postgres
    restart: unless-stopped
   
  airflow-init:
    image: apache/airflow:2.9.1
    container_name: airflow-init
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: 10
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    volumes:
      - ./dags:/opt/airflow/dags
    command: bash -c "
      airflow db init &&
      airflow connections add postgres_ohlc --conn-type postgres --conn-host postgres --conn-login airflow --conn-password airflow --conn-port 5432 --conn-schema airflow &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"

  airflow-webserver:
    image: apache/airflow:2.9.1
    container_name: airflow-webserver
    depends_on:
      - postgres
      - airflow-init
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW_UID: 50000
    command: webserver
    restart: always
    volumes:
      - ./dags:/opt/airflow/dags

  airflow-scheduler:
    image: apache/airflow:2.9.1
    container_name: airflow-scheduler
    depends_on:
      - postgres
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: 10
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW_UID: 50000
    command: scheduler
    restart: always
    volumes:
      - ./dags:/opt/airflow/dags
 
  superset:
    image: apache/superset:2.1.0
    container_name: superset
    depends_on:
      - postgres
    ports:
      - "8088:8088"
    environment:
      SUPERSET_WEBSERVER_PORT: 8088
      SUPERSET_SECRET_KEY: 'aP9v3kLz8xQ2mN1oR5t6w7y8z9A0bC1dE2fG3hI4jK5lM6nO7pQ8rT9uV0wX1yZ'
      SUPERSET_SQLALCHEMY_DATABASE_URI: 'postgresql+psycopg2://airflow:airflow@postgres:5432/airflow'
    command: >
      /bin/bash -c "
      pip install pillow psycopg2-binary &&
      superset db upgrade &&
      superset init &&
      superset fab create-admin --username admin --password admin --firstname Admin --lastname User --email admin@example.com &&
      superset run -h 0.0.0.0 -p 8088"
    restart: always

  superset_charts_creator:
    build:
      context: ./superset
      dockerfile: Dockerfile
    container_name: charts_creator
    depends_on:
      - kafka
      - postgres
      - superset
    entrypoint: >
      /bin/sh -c "
      echo 'Waiting for Superset to be ready...' &&
      while ! curl -s http://superset:8088/api/v1/security/login > /dev/null; do
        sleep 5
      done &&
      echo 'Superset is ready!' &&
      python charts_creator.py"
    restart: on-failure

volumes:
  postgres_data:


